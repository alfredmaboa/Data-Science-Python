{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_decision_tree_student_version-994.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1jwAw3vLLzr",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree Regression on the World Population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-O6chLjLLzs",
        "colab_type": "text"
      },
      "source": [
        "In this test we'll train a simple decision tree model using the world population data from the Analyse Supplementary Exam. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebtsqw6BLLzt",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CbY5ipnLLzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5PTnNvQLLzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "population_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/AnalyseProject/world_population.csv', index_col='Country Code')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baCVNg4ZLLz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "252ec605-109c-4a64-8f84-91830478c817"
      },
      "source": [
        "population_df.head()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1960</th>\n",
              "      <th>1961</th>\n",
              "      <th>1962</th>\n",
              "      <th>1963</th>\n",
              "      <th>1964</th>\n",
              "      <th>1965</th>\n",
              "      <th>1966</th>\n",
              "      <th>1967</th>\n",
              "      <th>1968</th>\n",
              "      <th>1969</th>\n",
              "      <th>1970</th>\n",
              "      <th>1971</th>\n",
              "      <th>1972</th>\n",
              "      <th>1973</th>\n",
              "      <th>1974</th>\n",
              "      <th>1975</th>\n",
              "      <th>1976</th>\n",
              "      <th>1977</th>\n",
              "      <th>1978</th>\n",
              "      <th>1979</th>\n",
              "      <th>1980</th>\n",
              "      <th>1981</th>\n",
              "      <th>1982</th>\n",
              "      <th>1983</th>\n",
              "      <th>1984</th>\n",
              "      <th>1985</th>\n",
              "      <th>1986</th>\n",
              "      <th>1987</th>\n",
              "      <th>1988</th>\n",
              "      <th>1989</th>\n",
              "      <th>1990</th>\n",
              "      <th>1991</th>\n",
              "      <th>1992</th>\n",
              "      <th>1993</th>\n",
              "      <th>1994</th>\n",
              "      <th>1995</th>\n",
              "      <th>1996</th>\n",
              "      <th>1997</th>\n",
              "      <th>1998</th>\n",
              "      <th>1999</th>\n",
              "      <th>2000</th>\n",
              "      <th>2001</th>\n",
              "      <th>2002</th>\n",
              "      <th>2003</th>\n",
              "      <th>2004</th>\n",
              "      <th>2005</th>\n",
              "      <th>2006</th>\n",
              "      <th>2007</th>\n",
              "      <th>2008</th>\n",
              "      <th>2009</th>\n",
              "      <th>2010</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>2013</th>\n",
              "      <th>2014</th>\n",
              "      <th>2015</th>\n",
              "      <th>2016</th>\n",
              "      <th>2017</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Country Code</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ABW</th>\n",
              "      <td>54211.0</td>\n",
              "      <td>55438.0</td>\n",
              "      <td>56225.0</td>\n",
              "      <td>56695.0</td>\n",
              "      <td>57032.0</td>\n",
              "      <td>57360.0</td>\n",
              "      <td>57715.0</td>\n",
              "      <td>58055.0</td>\n",
              "      <td>58386.0</td>\n",
              "      <td>58726.0</td>\n",
              "      <td>59063.0</td>\n",
              "      <td>59440.0</td>\n",
              "      <td>59840.0</td>\n",
              "      <td>60243.0</td>\n",
              "      <td>60528.0</td>\n",
              "      <td>60657.0</td>\n",
              "      <td>60586.0</td>\n",
              "      <td>60366.0</td>\n",
              "      <td>60103.0</td>\n",
              "      <td>59980.0</td>\n",
              "      <td>60096.0</td>\n",
              "      <td>60567.0</td>\n",
              "      <td>61345.0</td>\n",
              "      <td>62201.0</td>\n",
              "      <td>62836.0</td>\n",
              "      <td>63026.0</td>\n",
              "      <td>62644.0</td>\n",
              "      <td>61833.0</td>\n",
              "      <td>61079.0</td>\n",
              "      <td>61032.0</td>\n",
              "      <td>62149.0</td>\n",
              "      <td>64622.0</td>\n",
              "      <td>68235.0</td>\n",
              "      <td>72504.0</td>\n",
              "      <td>76700.0</td>\n",
              "      <td>80324.0</td>\n",
              "      <td>83200.0</td>\n",
              "      <td>85451.0</td>\n",
              "      <td>87277.0</td>\n",
              "      <td>89005.0</td>\n",
              "      <td>90853.0</td>\n",
              "      <td>92898.0</td>\n",
              "      <td>94992.0</td>\n",
              "      <td>97017.0</td>\n",
              "      <td>98737.0</td>\n",
              "      <td>100031.0</td>\n",
              "      <td>100832.0</td>\n",
              "      <td>101220.0</td>\n",
              "      <td>101353.0</td>\n",
              "      <td>101453.0</td>\n",
              "      <td>101669.0</td>\n",
              "      <td>102053.0</td>\n",
              "      <td>102577.0</td>\n",
              "      <td>103187.0</td>\n",
              "      <td>103795.0</td>\n",
              "      <td>104341.0</td>\n",
              "      <td>104822.0</td>\n",
              "      <td>105264.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFG</th>\n",
              "      <td>8996351.0</td>\n",
              "      <td>9166764.0</td>\n",
              "      <td>9345868.0</td>\n",
              "      <td>9533954.0</td>\n",
              "      <td>9731361.0</td>\n",
              "      <td>9938414.0</td>\n",
              "      <td>10152331.0</td>\n",
              "      <td>10372630.0</td>\n",
              "      <td>10604346.0</td>\n",
              "      <td>10854428.0</td>\n",
              "      <td>11126123.0</td>\n",
              "      <td>11417825.0</td>\n",
              "      <td>11721940.0</td>\n",
              "      <td>12027822.0</td>\n",
              "      <td>12321541.0</td>\n",
              "      <td>12590286.0</td>\n",
              "      <td>12840299.0</td>\n",
              "      <td>13067538.0</td>\n",
              "      <td>13237734.0</td>\n",
              "      <td>13306695.0</td>\n",
              "      <td>13248370.0</td>\n",
              "      <td>13053954.0</td>\n",
              "      <td>12749645.0</td>\n",
              "      <td>12389269.0</td>\n",
              "      <td>12047115.0</td>\n",
              "      <td>11783050.0</td>\n",
              "      <td>11601041.0</td>\n",
              "      <td>11502761.0</td>\n",
              "      <td>11540888.0</td>\n",
              "      <td>11777609.0</td>\n",
              "      <td>12249114.0</td>\n",
              "      <td>12993657.0</td>\n",
              "      <td>13981231.0</td>\n",
              "      <td>15095099.0</td>\n",
              "      <td>16172719.0</td>\n",
              "      <td>17099541.0</td>\n",
              "      <td>17822884.0</td>\n",
              "      <td>18381605.0</td>\n",
              "      <td>18863999.0</td>\n",
              "      <td>19403676.0</td>\n",
              "      <td>20093756.0</td>\n",
              "      <td>20966463.0</td>\n",
              "      <td>21979923.0</td>\n",
              "      <td>23064851.0</td>\n",
              "      <td>24118979.0</td>\n",
              "      <td>25070798.0</td>\n",
              "      <td>25893450.0</td>\n",
              "      <td>26616792.0</td>\n",
              "      <td>27294031.0</td>\n",
              "      <td>28004331.0</td>\n",
              "      <td>28803167.0</td>\n",
              "      <td>29708599.0</td>\n",
              "      <td>30696958.0</td>\n",
              "      <td>31731688.0</td>\n",
              "      <td>32758020.0</td>\n",
              "      <td>33736494.0</td>\n",
              "      <td>34656032.0</td>\n",
              "      <td>35530081.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGO</th>\n",
              "      <td>5643182.0</td>\n",
              "      <td>5753024.0</td>\n",
              "      <td>5866061.0</td>\n",
              "      <td>5980417.0</td>\n",
              "      <td>6093321.0</td>\n",
              "      <td>6203299.0</td>\n",
              "      <td>6309770.0</td>\n",
              "      <td>6414995.0</td>\n",
              "      <td>6523791.0</td>\n",
              "      <td>6642632.0</td>\n",
              "      <td>6776381.0</td>\n",
              "      <td>6927269.0</td>\n",
              "      <td>7094834.0</td>\n",
              "      <td>7277960.0</td>\n",
              "      <td>7474338.0</td>\n",
              "      <td>7682479.0</td>\n",
              "      <td>7900997.0</td>\n",
              "      <td>8130988.0</td>\n",
              "      <td>8376147.0</td>\n",
              "      <td>8641521.0</td>\n",
              "      <td>8929900.0</td>\n",
              "      <td>9244507.0</td>\n",
              "      <td>9582156.0</td>\n",
              "      <td>9931562.0</td>\n",
              "      <td>10277321.0</td>\n",
              "      <td>10609042.0</td>\n",
              "      <td>10921037.0</td>\n",
              "      <td>11218268.0</td>\n",
              "      <td>11513968.0</td>\n",
              "      <td>11827237.0</td>\n",
              "      <td>12171441.0</td>\n",
              "      <td>12553446.0</td>\n",
              "      <td>12968345.0</td>\n",
              "      <td>13403734.0</td>\n",
              "      <td>13841301.0</td>\n",
              "      <td>14268994.0</td>\n",
              "      <td>14682284.0</td>\n",
              "      <td>15088981.0</td>\n",
              "      <td>15504318.0</td>\n",
              "      <td>15949766.0</td>\n",
              "      <td>16440924.0</td>\n",
              "      <td>16983266.0</td>\n",
              "      <td>17572649.0</td>\n",
              "      <td>18203369.0</td>\n",
              "      <td>18865716.0</td>\n",
              "      <td>19552542.0</td>\n",
              "      <td>20262399.0</td>\n",
              "      <td>20997687.0</td>\n",
              "      <td>21759420.0</td>\n",
              "      <td>22549547.0</td>\n",
              "      <td>23369131.0</td>\n",
              "      <td>24218565.0</td>\n",
              "      <td>25096150.0</td>\n",
              "      <td>25998340.0</td>\n",
              "      <td>26920466.0</td>\n",
              "      <td>27859305.0</td>\n",
              "      <td>28813463.0</td>\n",
              "      <td>29784193.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ALB</th>\n",
              "      <td>1608800.0</td>\n",
              "      <td>1659800.0</td>\n",
              "      <td>1711319.0</td>\n",
              "      <td>1762621.0</td>\n",
              "      <td>1814135.0</td>\n",
              "      <td>1864791.0</td>\n",
              "      <td>1914573.0</td>\n",
              "      <td>1965598.0</td>\n",
              "      <td>2022272.0</td>\n",
              "      <td>2081695.0</td>\n",
              "      <td>2135479.0</td>\n",
              "      <td>2187853.0</td>\n",
              "      <td>2243126.0</td>\n",
              "      <td>2296752.0</td>\n",
              "      <td>2350124.0</td>\n",
              "      <td>2404831.0</td>\n",
              "      <td>2458526.0</td>\n",
              "      <td>2513546.0</td>\n",
              "      <td>2566266.0</td>\n",
              "      <td>2617832.0</td>\n",
              "      <td>2671997.0</td>\n",
              "      <td>2726056.0</td>\n",
              "      <td>2784278.0</td>\n",
              "      <td>2843960.0</td>\n",
              "      <td>2904429.0</td>\n",
              "      <td>2964762.0</td>\n",
              "      <td>3022635.0</td>\n",
              "      <td>3083605.0</td>\n",
              "      <td>3142336.0</td>\n",
              "      <td>3227943.0</td>\n",
              "      <td>3286542.0</td>\n",
              "      <td>3266790.0</td>\n",
              "      <td>3247039.0</td>\n",
              "      <td>3227287.0</td>\n",
              "      <td>3207536.0</td>\n",
              "      <td>3187784.0</td>\n",
              "      <td>3168033.0</td>\n",
              "      <td>3148281.0</td>\n",
              "      <td>3128530.0</td>\n",
              "      <td>3108778.0</td>\n",
              "      <td>3089027.0</td>\n",
              "      <td>3060173.0</td>\n",
              "      <td>3051010.0</td>\n",
              "      <td>3039616.0</td>\n",
              "      <td>3026939.0</td>\n",
              "      <td>3011487.0</td>\n",
              "      <td>2992547.0</td>\n",
              "      <td>2970017.0</td>\n",
              "      <td>2947314.0</td>\n",
              "      <td>2927519.0</td>\n",
              "      <td>2913021.0</td>\n",
              "      <td>2905195.0</td>\n",
              "      <td>2900401.0</td>\n",
              "      <td>2895092.0</td>\n",
              "      <td>2889104.0</td>\n",
              "      <td>2880703.0</td>\n",
              "      <td>2876101.0</td>\n",
              "      <td>2873457.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AND</th>\n",
              "      <td>13411.0</td>\n",
              "      <td>14375.0</td>\n",
              "      <td>15370.0</td>\n",
              "      <td>16412.0</td>\n",
              "      <td>17469.0</td>\n",
              "      <td>18549.0</td>\n",
              "      <td>19647.0</td>\n",
              "      <td>20758.0</td>\n",
              "      <td>21890.0</td>\n",
              "      <td>23058.0</td>\n",
              "      <td>24276.0</td>\n",
              "      <td>25559.0</td>\n",
              "      <td>26892.0</td>\n",
              "      <td>28232.0</td>\n",
              "      <td>29520.0</td>\n",
              "      <td>30705.0</td>\n",
              "      <td>31777.0</td>\n",
              "      <td>32771.0</td>\n",
              "      <td>33737.0</td>\n",
              "      <td>34818.0</td>\n",
              "      <td>36067.0</td>\n",
              "      <td>37500.0</td>\n",
              "      <td>39114.0</td>\n",
              "      <td>40867.0</td>\n",
              "      <td>42706.0</td>\n",
              "      <td>44600.0</td>\n",
              "      <td>46517.0</td>\n",
              "      <td>48455.0</td>\n",
              "      <td>50434.0</td>\n",
              "      <td>52448.0</td>\n",
              "      <td>54509.0</td>\n",
              "      <td>56671.0</td>\n",
              "      <td>58888.0</td>\n",
              "      <td>60971.0</td>\n",
              "      <td>62677.0</td>\n",
              "      <td>63850.0</td>\n",
              "      <td>64360.0</td>\n",
              "      <td>64327.0</td>\n",
              "      <td>64142.0</td>\n",
              "      <td>64370.0</td>\n",
              "      <td>65390.0</td>\n",
              "      <td>67341.0</td>\n",
              "      <td>70049.0</td>\n",
              "      <td>73182.0</td>\n",
              "      <td>76244.0</td>\n",
              "      <td>78867.0</td>\n",
              "      <td>80991.0</td>\n",
              "      <td>82683.0</td>\n",
              "      <td>83861.0</td>\n",
              "      <td>84462.0</td>\n",
              "      <td>84449.0</td>\n",
              "      <td>83751.0</td>\n",
              "      <td>82431.0</td>\n",
              "      <td>80788.0</td>\n",
              "      <td>79223.0</td>\n",
              "      <td>78014.0</td>\n",
              "      <td>77281.0</td>\n",
              "      <td>76965.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   1960       1961  ...        2016        2017\n",
              "Country Code                        ...                        \n",
              "ABW             54211.0    55438.0  ...    104822.0    105264.0\n",
              "AFG           8996351.0  9166764.0  ...  34656032.0  35530081.0\n",
              "AGO           5643182.0  5753024.0  ...  28813463.0  29784193.0\n",
              "ALB           1608800.0  1659800.0  ...   2876101.0   2873457.0\n",
              "AND             13411.0    14375.0  ...     77281.0     76965.0\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiLVW2AhLLz6",
        "colab_type": "text"
      },
      "source": [
        "### Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRLFJca-LLz7",
        "colab_type": "text"
      },
      "source": [
        "The world population data spans from 1960 to 2017. We'd like to build a predictive model that can give us the best guess at what the future world population in a given year might be. To do this, we're going to ignore the 2017 column from our data, and use this as a metric for testing the accuracy of our prediction.\n",
        "\n",
        "Since the given dataframe (`population_df`) only has population by country per year, we need to find the **total** world population for each year. To achieve this, we'll write a function that computes the sum of the populations of the different countries in `population_df` for each year. This function must return a \n",
        "return a 2-d numpy array that contains the year and the total world population.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should have no input and return a numpy `array` type as output.\n",
        "* The array should only have two columns containing the year and the population, in other words, it should have a shape `(?, 2)` where `?` is the length of the data.\n",
        "* The values within the array should be of type `np.int64`.\n",
        "\n",
        "_**Further Reading:**_\n",
        "\n",
        "Data types are associated with memory allocation. As such, your choice of data type affects the precision of computations in your program. For example, the `np.int` data type in numpy can only store values between -2147483648 to 2147483647 and assigning values outside this range for variables of this data type may cause run-time errors. To avoid this, we can use data types with larger memory capacity e.g. `np.int64`.\n",
        "\n",
        "https://docs.scipy.org/doc/numpy/user/basics.types.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gaIzVa3LLz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_total_population_by_country_year():\n",
        "    \n",
        "    df = pd.DataFrame(population_df)\n",
        "    #df = df.drop(['2017'],axis=1)\n",
        "    df = pd.melt(df, var_name='Year', value_name='Population')\n",
        "    df =df.groupby(['Year'])[['Population']].sum()\n",
        "    #df = df.drop(['Country Code'],axis=1) \n",
        "    array_1 = df['Population'].astype(np.int64)  \n",
        "    array_2 = df.index.astype(np.int64)\n",
        "    \n",
        "    df=pd.DataFrame({'Year' : array_2,'Population' : array_1})\n",
        "    return np.array(df,dtype='int64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o030rRwzLLz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1003
        },
        "outputId": "2bb3b5e2-089a-47cf-bbc8-46edc67936de"
      },
      "source": [
        "get_total_population_by_country_year()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[      1960, 3014940395],\n",
              "       [      1961, 3055691989],\n",
              "       [      1962, 3108379009],\n",
              "       [      1963, 3173207428],\n",
              "       [      1964, 3238441149],\n",
              "       [      1965, 3305101319],\n",
              "       [      1966, 3374903353],\n",
              "       [      1967, 3444384585],\n",
              "       [      1968, 3514639116],\n",
              "       [      1969, 3589069293],\n",
              "       [      1970, 3664271341],\n",
              "       [      1971, 3741545439],\n",
              "       [      1972, 3818075376],\n",
              "       [      1973, 3893726301],\n",
              "       [      1974, 3970035481],\n",
              "       [      1975, 4044577268],\n",
              "       [      1976, 4117105339],\n",
              "       [      1977, 4189387395],\n",
              "       [      1978, 4262884975],\n",
              "       [      1979, 4338225244],\n",
              "       [      1980, 4414334568],\n",
              "       [      1981, 4492427948],\n",
              "       [      1982, 4573445316],\n",
              "       [      1983, 4655199096],\n",
              "       [      1984, 4736682102],\n",
              "       [      1985, 4819699772],\n",
              "       [      1986, 4905221325],\n",
              "       [      1987, 4992879504],\n",
              "       [      1988, 5081453078],\n",
              "       [      1989, 5170171686],\n",
              "       [      1990, 5267861414],\n",
              "       [      1991, 5355034619],\n",
              "       [      1992, 5439046865],\n",
              "       [      1993, 5523974088],\n",
              "       [      1994, 5607765176],\n",
              "       [      1995, 5692526372],\n",
              "       [      1996, 5775191117],\n",
              "       [      1997, 5857799900],\n",
              "       [      1998, 5939330037],\n",
              "       [      1999, 6019808586],\n",
              "       [      2000, 6099498206],\n",
              "       [      2001, 6178999138],\n",
              "       [      2002, 6258066893],\n",
              "       [      2003, 6337336633],\n",
              "       [      2004, 6417178545],\n",
              "       [      2005, 6497569010],\n",
              "       [      2006, 6578653086],\n",
              "       [      2007, 6660306328],\n",
              "       [      2008, 6743298983],\n",
              "       [      2009, 6826490839],\n",
              "       [      2010, 6909731743],\n",
              "       [      2011, 6991803968],\n",
              "       [      2012, 7071734672],\n",
              "       [      2013, 7157142528],\n",
              "       [      2014, 7243184776],\n",
              "       [      2015, 7329250474],\n",
              "       [      2016, 7415694711],\n",
              "       [      2017, 7501739318]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAlgnJsaLL0A",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "total_population_by_country_year()\n",
        "```\n",
        "> ```\n",
        "array([[      1960, 3014940395],\n",
        "       [      1961, 3055691989],\n",
        "       [      1962, 3108379009],\n",
        "       [      1963, 3173207428],\n",
        "        ...\n",
        "       [      2015, 7329250474],\n",
        "       [      2016, 7415694711],\n",
        "       [      2017, 7501739318]], dtype=int64)`\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkrs4HZSLL0B",
        "colab_type": "text"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Now that we have have our data, we need to split this into a set of variables we will be training on, and the set of variables that we will make our predictions on. In this case, we're splitting the values such that we train on all but the last year in our dataset. We also need to split our data into the predictive features (denoted `X`) and the response (denoted `y`). \n",
        "\n",
        "Write a function that will take as input a 2-d numpy array and return four variables in the form of `(X_train, y_train), (X_test, y_test)`, where `(X_train, y_train)` are the features / response of the training set, and `(X-test, y_test)` are the feautes / response of the testing set.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take a 2-d numpy `array` as input.\n",
        "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`.\n",
        "* `(X_test, y_test)` should just be the last entry of the given input. They should also be the form of an `array`, and not as a single value.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1whr5ur8LL0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_response_split(arr):\n",
        "    X_train = arr[0:-1,0]\n",
        "    y_train = arr[0:-1,1]\n",
        "    X_test =arr[-1:,0]\n",
        "    y_test =arr[-1:,1]\n",
        "    return (X_train, y_train), (X_test, y_test)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y4KdJIxLL0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "6c37f583-cf86-41a3-a0b9-b98677d8b051"
      },
      "source": [
        "data = get_total_population_by_country_year()\n",
        "feature_response_split(data)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970,\n",
              "         1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981,\n",
              "         1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992,\n",
              "         1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003,\n",
              "         2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,\n",
              "         2015, 2016]),\n",
              "  array([3014940395, 3055691989, 3108379009, 3173207428, 3238441149,\n",
              "         3305101319, 3374903353, 3444384585, 3514639116, 3589069293,\n",
              "         3664271341, 3741545439, 3818075376, 3893726301, 3970035481,\n",
              "         4044577268, 4117105339, 4189387395, 4262884975, 4338225244,\n",
              "         4414334568, 4492427948, 4573445316, 4655199096, 4736682102,\n",
              "         4819699772, 4905221325, 4992879504, 5081453078, 5170171686,\n",
              "         5267861414, 5355034619, 5439046865, 5523974088, 5607765176,\n",
              "         5692526372, 5775191117, 5857799900, 5939330037, 6019808586,\n",
              "         6099498206, 6178999138, 6258066893, 6337336633, 6417178545,\n",
              "         6497569010, 6578653086, 6660306328, 6743298983, 6826490839,\n",
              "         6909731743, 6991803968, 7071734672, 7157142528, 7243184776,\n",
              "         7329250474, 7415694711])),\n",
              " (array([2017]), array([7501739318])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9bE8E8eLL0I",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "data = get_total_population_by_country_year()\n",
        "feature_response_split(data)\n",
        "```\n",
        "> ```\n",
        "((array([1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970,\n",
        "         1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981,\n",
        "         1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992,\n",
        "         1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003,\n",
        "         2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,\n",
        "         2015, 2016], dtype=int64),\n",
        "  array([3014940395, 3055691989, 3108379009, 3173207428, 3238441149,\n",
        "         3305101319, 3374903353, 3444384585, 3514639116, 3589069293,\n",
        "         3664271341, 3741545439, 3818075376, 3893726301, 3970035481,\n",
        "         4044577268, 4117105339, 4189387395, 4262884975, 4338225244,\n",
        "         4414334568, 4492427948, 4573445316, 4655199096, 4736682102,\n",
        "         4819699772, 4905221325, 4992879504, 5081453078, 5170171686,\n",
        "         5267861414, 5355034619, 5439046865, 5523974088, 5607765176,\n",
        "         5692526372, 5775191117, 5857799900, 5939330037, 6019808586,\n",
        "         6099498206, 6178999138, 6258066893, 6337336633, 6417178545,\n",
        "         6497569010, 6578653086, 6660306328, 6743298983, 6826490839,\n",
        "         6909731743, 6991803968, 7071734672, 7157142528, 7243184776,\n",
        "         7329250474, 7415694711], dtype=int64)),\n",
        " (array([2017], dtype=int64), array([7501739318], dtype=int64)))\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N7QHwvyLL0J",
        "colab_type": "text"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Now that we have formatted our data, we can fit a model using sklearn's `DecisionTreeRegressor` class. We'll write a function that will take as input the features and response variables that we created in the last question, and return a trained model.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
        "* Should return an sklearn `DecisionTreeRegressor` model.\n",
        "* The returned model should be fitted to the data.\n",
        "\n",
        "_**Hint:**_\n",
        "You may need to reshape the data within the function. You can use `.reshape(-1, 1)` to do this.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li41FO8rLL0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(X_train, y_train):\n",
        "    from sklearn.tree import DecisionTreeRegressor\n",
        "    reg = DecisionTreeRegressor()\n",
        "    reg.fit(X_train.reshape(-1, 1),y_train.reshape(-1, 1))\n",
        "    return reg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hYXrzoGLL0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29e4de2a-c650-4874-88c9-5837370bc450"
      },
      "source": [
        "data = get_total_population_by_country_year()\n",
        "(X_train, y_train), _ = feature_response_split(data)\n",
        "train_model(X_train, y_train).predict([[2017]])"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.41569471e+09])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoYkZoJGLL0P",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "train_model(X_train, y_train).predict([[2017]]) == array([[7.41569471e+09]])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12GQYFj8LL0Q",
        "colab_type": "text"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "We would now like to test on our testing data that we produced from Question 2. This test will give the Root Mean Squared Logarithmic Error (RMSLE), which is given by:\n",
        "\n",
        "$$\n",
        "RMSLE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N [log(1+p_i) - log(1+y_i)]^2}\n",
        "$$\n",
        "\n",
        "where $p_i$ refers to the $i^{\\rm th}$ prediction made from `X_test`, $y_i$ refers to the $i^{\\rm th}$ value in `y_test`, and $N$ is the length of `y_test`.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take a trained model and two `arrays` as input. This will be the `X_test` and `y_test` variables from Question 2. \n",
        "* Should return the residual sum of squares over the input from the predicted values of `X_test` as compared to values of `y_test`.\n",
        "* The output should be a `float` rounded to 3 decimal places.\n",
        "\n",
        "_**Hint:**_\n",
        "The Root Mean Squared Logarithmic Error is used to calculate the score in the kaggle House Prices Competition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzO2Fg-2LL0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, X_test, y_test):\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    y_pred = model.predict(X_test.reshape(-1,1))\n",
        "    return np.round(np.sqrt(np.mean(np.square(np.log1p(y_test.reshape(-1,1)) - np.log1p(y_pred)))),3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr3DWwuILL0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b3edf87-c2c0-4ebb-d9ab-8cfca969b1ad"
      },
      "source": [
        "data = get_total_population_by_country_year()\n",
        "(X_train, y_train), (X_test, y_test) = feature_response_split(data)\n",
        "lm = train_model(X_train, y_train)\n",
        "test_model(lm, X_test, y_test)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.012"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKGgkajuLL0V",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "test_model(lm, X_test, y_test) == 0.012\n",
        "```"
      ]
    }
  ]
}