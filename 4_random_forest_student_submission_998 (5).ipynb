{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_random_forest_student_submission-998.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBZK5RZjwsmv",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest Regression on the World Population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GopkZS1Vwsmx",
        "colab_type": "text"
      },
      "source": [
        "For the final test of the week, we'll learn how decision trees can be expanded upon as simple classifiers in order to create an [ensemble](https://en.wikipedia.org/wiki/Ensemble_learning) model know as a Random Forest. Like our previous coding challenges, we train this new model using the world population data from the Analyse Supplementary Exam. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjlJt2Txwsmy",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ThXiOAewsmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5bj8RTHwsm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "population_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/AnalyseProject/world_population.csv', index_col='Country Code')\n",
        "meta_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/AnalyseProject/metadata.csv', index_col='Country Code')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIWNmoBZwsm6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "48128b75-ea49-48d1-c3dd-71e07fffab4f"
      },
      "source": [
        "population_df.head()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1960</th>\n",
              "      <th>1961</th>\n",
              "      <th>1962</th>\n",
              "      <th>1963</th>\n",
              "      <th>1964</th>\n",
              "      <th>1965</th>\n",
              "      <th>1966</th>\n",
              "      <th>1967</th>\n",
              "      <th>1968</th>\n",
              "      <th>1969</th>\n",
              "      <th>1970</th>\n",
              "      <th>1971</th>\n",
              "      <th>1972</th>\n",
              "      <th>1973</th>\n",
              "      <th>1974</th>\n",
              "      <th>1975</th>\n",
              "      <th>1976</th>\n",
              "      <th>1977</th>\n",
              "      <th>1978</th>\n",
              "      <th>1979</th>\n",
              "      <th>1980</th>\n",
              "      <th>1981</th>\n",
              "      <th>1982</th>\n",
              "      <th>1983</th>\n",
              "      <th>1984</th>\n",
              "      <th>1985</th>\n",
              "      <th>1986</th>\n",
              "      <th>1987</th>\n",
              "      <th>1988</th>\n",
              "      <th>1989</th>\n",
              "      <th>1990</th>\n",
              "      <th>1991</th>\n",
              "      <th>1992</th>\n",
              "      <th>1993</th>\n",
              "      <th>1994</th>\n",
              "      <th>1995</th>\n",
              "      <th>1996</th>\n",
              "      <th>1997</th>\n",
              "      <th>1998</th>\n",
              "      <th>1999</th>\n",
              "      <th>2000</th>\n",
              "      <th>2001</th>\n",
              "      <th>2002</th>\n",
              "      <th>2003</th>\n",
              "      <th>2004</th>\n",
              "      <th>2005</th>\n",
              "      <th>2006</th>\n",
              "      <th>2007</th>\n",
              "      <th>2008</th>\n",
              "      <th>2009</th>\n",
              "      <th>2010</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>2013</th>\n",
              "      <th>2014</th>\n",
              "      <th>2015</th>\n",
              "      <th>2016</th>\n",
              "      <th>2017</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Country Code</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ABW</th>\n",
              "      <td>54211.0</td>\n",
              "      <td>55438.0</td>\n",
              "      <td>56225.0</td>\n",
              "      <td>56695.0</td>\n",
              "      <td>57032.0</td>\n",
              "      <td>57360.0</td>\n",
              "      <td>57715.0</td>\n",
              "      <td>58055.0</td>\n",
              "      <td>58386.0</td>\n",
              "      <td>58726.0</td>\n",
              "      <td>59063.0</td>\n",
              "      <td>59440.0</td>\n",
              "      <td>59840.0</td>\n",
              "      <td>60243.0</td>\n",
              "      <td>60528.0</td>\n",
              "      <td>60657.0</td>\n",
              "      <td>60586.0</td>\n",
              "      <td>60366.0</td>\n",
              "      <td>60103.0</td>\n",
              "      <td>59980.0</td>\n",
              "      <td>60096.0</td>\n",
              "      <td>60567.0</td>\n",
              "      <td>61345.0</td>\n",
              "      <td>62201.0</td>\n",
              "      <td>62836.0</td>\n",
              "      <td>63026.0</td>\n",
              "      <td>62644.0</td>\n",
              "      <td>61833.0</td>\n",
              "      <td>61079.0</td>\n",
              "      <td>61032.0</td>\n",
              "      <td>62149.0</td>\n",
              "      <td>64622.0</td>\n",
              "      <td>68235.0</td>\n",
              "      <td>72504.0</td>\n",
              "      <td>76700.0</td>\n",
              "      <td>80324.0</td>\n",
              "      <td>83200.0</td>\n",
              "      <td>85451.0</td>\n",
              "      <td>87277.0</td>\n",
              "      <td>89005.0</td>\n",
              "      <td>90853.0</td>\n",
              "      <td>92898.0</td>\n",
              "      <td>94992.0</td>\n",
              "      <td>97017.0</td>\n",
              "      <td>98737.0</td>\n",
              "      <td>100031.0</td>\n",
              "      <td>100832.0</td>\n",
              "      <td>101220.0</td>\n",
              "      <td>101353.0</td>\n",
              "      <td>101453.0</td>\n",
              "      <td>101669.0</td>\n",
              "      <td>102053.0</td>\n",
              "      <td>102577.0</td>\n",
              "      <td>103187.0</td>\n",
              "      <td>103795.0</td>\n",
              "      <td>104341.0</td>\n",
              "      <td>104822.0</td>\n",
              "      <td>105264.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFG</th>\n",
              "      <td>8996351.0</td>\n",
              "      <td>9166764.0</td>\n",
              "      <td>9345868.0</td>\n",
              "      <td>9533954.0</td>\n",
              "      <td>9731361.0</td>\n",
              "      <td>9938414.0</td>\n",
              "      <td>10152331.0</td>\n",
              "      <td>10372630.0</td>\n",
              "      <td>10604346.0</td>\n",
              "      <td>10854428.0</td>\n",
              "      <td>11126123.0</td>\n",
              "      <td>11417825.0</td>\n",
              "      <td>11721940.0</td>\n",
              "      <td>12027822.0</td>\n",
              "      <td>12321541.0</td>\n",
              "      <td>12590286.0</td>\n",
              "      <td>12840299.0</td>\n",
              "      <td>13067538.0</td>\n",
              "      <td>13237734.0</td>\n",
              "      <td>13306695.0</td>\n",
              "      <td>13248370.0</td>\n",
              "      <td>13053954.0</td>\n",
              "      <td>12749645.0</td>\n",
              "      <td>12389269.0</td>\n",
              "      <td>12047115.0</td>\n",
              "      <td>11783050.0</td>\n",
              "      <td>11601041.0</td>\n",
              "      <td>11502761.0</td>\n",
              "      <td>11540888.0</td>\n",
              "      <td>11777609.0</td>\n",
              "      <td>12249114.0</td>\n",
              "      <td>12993657.0</td>\n",
              "      <td>13981231.0</td>\n",
              "      <td>15095099.0</td>\n",
              "      <td>16172719.0</td>\n",
              "      <td>17099541.0</td>\n",
              "      <td>17822884.0</td>\n",
              "      <td>18381605.0</td>\n",
              "      <td>18863999.0</td>\n",
              "      <td>19403676.0</td>\n",
              "      <td>20093756.0</td>\n",
              "      <td>20966463.0</td>\n",
              "      <td>21979923.0</td>\n",
              "      <td>23064851.0</td>\n",
              "      <td>24118979.0</td>\n",
              "      <td>25070798.0</td>\n",
              "      <td>25893450.0</td>\n",
              "      <td>26616792.0</td>\n",
              "      <td>27294031.0</td>\n",
              "      <td>28004331.0</td>\n",
              "      <td>28803167.0</td>\n",
              "      <td>29708599.0</td>\n",
              "      <td>30696958.0</td>\n",
              "      <td>31731688.0</td>\n",
              "      <td>32758020.0</td>\n",
              "      <td>33736494.0</td>\n",
              "      <td>34656032.0</td>\n",
              "      <td>35530081.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGO</th>\n",
              "      <td>5643182.0</td>\n",
              "      <td>5753024.0</td>\n",
              "      <td>5866061.0</td>\n",
              "      <td>5980417.0</td>\n",
              "      <td>6093321.0</td>\n",
              "      <td>6203299.0</td>\n",
              "      <td>6309770.0</td>\n",
              "      <td>6414995.0</td>\n",
              "      <td>6523791.0</td>\n",
              "      <td>6642632.0</td>\n",
              "      <td>6776381.0</td>\n",
              "      <td>6927269.0</td>\n",
              "      <td>7094834.0</td>\n",
              "      <td>7277960.0</td>\n",
              "      <td>7474338.0</td>\n",
              "      <td>7682479.0</td>\n",
              "      <td>7900997.0</td>\n",
              "      <td>8130988.0</td>\n",
              "      <td>8376147.0</td>\n",
              "      <td>8641521.0</td>\n",
              "      <td>8929900.0</td>\n",
              "      <td>9244507.0</td>\n",
              "      <td>9582156.0</td>\n",
              "      <td>9931562.0</td>\n",
              "      <td>10277321.0</td>\n",
              "      <td>10609042.0</td>\n",
              "      <td>10921037.0</td>\n",
              "      <td>11218268.0</td>\n",
              "      <td>11513968.0</td>\n",
              "      <td>11827237.0</td>\n",
              "      <td>12171441.0</td>\n",
              "      <td>12553446.0</td>\n",
              "      <td>12968345.0</td>\n",
              "      <td>13403734.0</td>\n",
              "      <td>13841301.0</td>\n",
              "      <td>14268994.0</td>\n",
              "      <td>14682284.0</td>\n",
              "      <td>15088981.0</td>\n",
              "      <td>15504318.0</td>\n",
              "      <td>15949766.0</td>\n",
              "      <td>16440924.0</td>\n",
              "      <td>16983266.0</td>\n",
              "      <td>17572649.0</td>\n",
              "      <td>18203369.0</td>\n",
              "      <td>18865716.0</td>\n",
              "      <td>19552542.0</td>\n",
              "      <td>20262399.0</td>\n",
              "      <td>20997687.0</td>\n",
              "      <td>21759420.0</td>\n",
              "      <td>22549547.0</td>\n",
              "      <td>23369131.0</td>\n",
              "      <td>24218565.0</td>\n",
              "      <td>25096150.0</td>\n",
              "      <td>25998340.0</td>\n",
              "      <td>26920466.0</td>\n",
              "      <td>27859305.0</td>\n",
              "      <td>28813463.0</td>\n",
              "      <td>29784193.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ALB</th>\n",
              "      <td>1608800.0</td>\n",
              "      <td>1659800.0</td>\n",
              "      <td>1711319.0</td>\n",
              "      <td>1762621.0</td>\n",
              "      <td>1814135.0</td>\n",
              "      <td>1864791.0</td>\n",
              "      <td>1914573.0</td>\n",
              "      <td>1965598.0</td>\n",
              "      <td>2022272.0</td>\n",
              "      <td>2081695.0</td>\n",
              "      <td>2135479.0</td>\n",
              "      <td>2187853.0</td>\n",
              "      <td>2243126.0</td>\n",
              "      <td>2296752.0</td>\n",
              "      <td>2350124.0</td>\n",
              "      <td>2404831.0</td>\n",
              "      <td>2458526.0</td>\n",
              "      <td>2513546.0</td>\n",
              "      <td>2566266.0</td>\n",
              "      <td>2617832.0</td>\n",
              "      <td>2671997.0</td>\n",
              "      <td>2726056.0</td>\n",
              "      <td>2784278.0</td>\n",
              "      <td>2843960.0</td>\n",
              "      <td>2904429.0</td>\n",
              "      <td>2964762.0</td>\n",
              "      <td>3022635.0</td>\n",
              "      <td>3083605.0</td>\n",
              "      <td>3142336.0</td>\n",
              "      <td>3227943.0</td>\n",
              "      <td>3286542.0</td>\n",
              "      <td>3266790.0</td>\n",
              "      <td>3247039.0</td>\n",
              "      <td>3227287.0</td>\n",
              "      <td>3207536.0</td>\n",
              "      <td>3187784.0</td>\n",
              "      <td>3168033.0</td>\n",
              "      <td>3148281.0</td>\n",
              "      <td>3128530.0</td>\n",
              "      <td>3108778.0</td>\n",
              "      <td>3089027.0</td>\n",
              "      <td>3060173.0</td>\n",
              "      <td>3051010.0</td>\n",
              "      <td>3039616.0</td>\n",
              "      <td>3026939.0</td>\n",
              "      <td>3011487.0</td>\n",
              "      <td>2992547.0</td>\n",
              "      <td>2970017.0</td>\n",
              "      <td>2947314.0</td>\n",
              "      <td>2927519.0</td>\n",
              "      <td>2913021.0</td>\n",
              "      <td>2905195.0</td>\n",
              "      <td>2900401.0</td>\n",
              "      <td>2895092.0</td>\n",
              "      <td>2889104.0</td>\n",
              "      <td>2880703.0</td>\n",
              "      <td>2876101.0</td>\n",
              "      <td>2873457.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AND</th>\n",
              "      <td>13411.0</td>\n",
              "      <td>14375.0</td>\n",
              "      <td>15370.0</td>\n",
              "      <td>16412.0</td>\n",
              "      <td>17469.0</td>\n",
              "      <td>18549.0</td>\n",
              "      <td>19647.0</td>\n",
              "      <td>20758.0</td>\n",
              "      <td>21890.0</td>\n",
              "      <td>23058.0</td>\n",
              "      <td>24276.0</td>\n",
              "      <td>25559.0</td>\n",
              "      <td>26892.0</td>\n",
              "      <td>28232.0</td>\n",
              "      <td>29520.0</td>\n",
              "      <td>30705.0</td>\n",
              "      <td>31777.0</td>\n",
              "      <td>32771.0</td>\n",
              "      <td>33737.0</td>\n",
              "      <td>34818.0</td>\n",
              "      <td>36067.0</td>\n",
              "      <td>37500.0</td>\n",
              "      <td>39114.0</td>\n",
              "      <td>40867.0</td>\n",
              "      <td>42706.0</td>\n",
              "      <td>44600.0</td>\n",
              "      <td>46517.0</td>\n",
              "      <td>48455.0</td>\n",
              "      <td>50434.0</td>\n",
              "      <td>52448.0</td>\n",
              "      <td>54509.0</td>\n",
              "      <td>56671.0</td>\n",
              "      <td>58888.0</td>\n",
              "      <td>60971.0</td>\n",
              "      <td>62677.0</td>\n",
              "      <td>63850.0</td>\n",
              "      <td>64360.0</td>\n",
              "      <td>64327.0</td>\n",
              "      <td>64142.0</td>\n",
              "      <td>64370.0</td>\n",
              "      <td>65390.0</td>\n",
              "      <td>67341.0</td>\n",
              "      <td>70049.0</td>\n",
              "      <td>73182.0</td>\n",
              "      <td>76244.0</td>\n",
              "      <td>78867.0</td>\n",
              "      <td>80991.0</td>\n",
              "      <td>82683.0</td>\n",
              "      <td>83861.0</td>\n",
              "      <td>84462.0</td>\n",
              "      <td>84449.0</td>\n",
              "      <td>83751.0</td>\n",
              "      <td>82431.0</td>\n",
              "      <td>80788.0</td>\n",
              "      <td>79223.0</td>\n",
              "      <td>78014.0</td>\n",
              "      <td>77281.0</td>\n",
              "      <td>76965.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   1960       1961  ...        2016        2017\n",
              "Country Code                        ...                        \n",
              "ABW             54211.0    55438.0  ...    104822.0    105264.0\n",
              "AFG           8996351.0  9166764.0  ...  34656032.0  35530081.0\n",
              "AGO           5643182.0  5753024.0  ...  28813463.0  29784193.0\n",
              "ALB           1608800.0  1659800.0  ...   2876101.0   2873457.0\n",
              "AND             13411.0    14375.0  ...     77281.0     76965.0\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfYyzaqowsnA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "422268ab-6508-4443-cb5b-227bb98cc5d5"
      },
      "source": [
        "meta_df.head()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Region</th>\n",
              "      <th>Income Group</th>\n",
              "      <th>Special Notes</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Country Code</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ABW</th>\n",
              "      <td>Latin America &amp; Caribbean</td>\n",
              "      <td>High income</td>\n",
              "      <td>Mining is included in agriculture\\r\\r\\r\\nElect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFG</th>\n",
              "      <td>South Asia</td>\n",
              "      <td>Low income</td>\n",
              "      <td>Fiscal year end: March 20; reporting period fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGO</th>\n",
              "      <td>Sub-Saharan Africa</td>\n",
              "      <td>Lower middle income</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ALB</th>\n",
              "      <td>Europe &amp; Central Asia</td>\n",
              "      <td>Upper middle income</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AND</th>\n",
              "      <td>Europe &amp; Central Asia</td>\n",
              "      <td>High income</td>\n",
              "      <td>WB-3 code changed from ADO to AND to align wit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Region  ...                                      Special Notes\n",
              "Country Code                             ...                                                   \n",
              "ABW           Latin America & Caribbean  ...  Mining is included in agriculture\\r\\r\\r\\nElect...\n",
              "AFG                          South Asia  ...  Fiscal year end: March 20; reporting period fo...\n",
              "AGO                  Sub-Saharan Africa  ...                                                NaN\n",
              "ALB               Europe & Central Asia  ...                                                NaN\n",
              "AND               Europe & Central Asia  ...  WB-3 code changed from ADO to AND to align wit...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOIe65ENwsnE",
        "colab_type": "text"
      },
      "source": [
        "### Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGfyU7RmwsnF",
        "colab_type": "text"
      },
      "source": [
        "As we've seen previously, the world population data spans from 1960 to 2017. We'd like to build a predictive model that can give us the best guess at what the world population in a given year was. However, as a slight twist this time, we want to compute this estimate for only _countries within a given income group_. To do this, similar to our previous coding challenges, we need to partition our data such that we have testing data which is reserved for our model's evaluation.  \n",
        "\n",
        "First, however, we need to formulate our data such that the sklearn's `RandomForestRegressor` class can train on our data. To do this, we will write a function that takes as input an income group and return a 2-d numpy array that contains the year and the measured population.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take a `str` argument, called `income_group` as input and return a numpy `array` type as output.\n",
        "* Set the default argument of `income_group` to equal `'Low income'`.\n",
        "* If the specified value of `income_group` does not exist, the function must raise a `ValueError`.\n",
        "* The array should only have two columns containing the year and the population, in other words, it should have a shape `(?, 2)` where `?` is the length of the data.\n",
        "* The values within the array should be of type `np.int64`. \n",
        "\n",
        "_**Further Reading:**_\n",
        "\n",
        "Data types are associated with memory allocation. As such, your choice of data type affects the precision of computations in your program. For example, the `np.int` data type in numpy can only store values between -2147483648 to 2147483647 and assigning values outside this range for variables of this data type may cause run-time errors. To avoid this, we can use data types with larger memory capacity e.g. `np.int64`.\n",
        "\n",
        "https://docs.scipy.org/doc/numpy/user/basics.types.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSYmO9tewsnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_year_pop_by_income(income_group='Low income'):\n",
        "    \n",
        "  x = list(['High income','Low income','Lower middle income', 'Upper middle income'])\n",
        "  if income_group not in x:\n",
        "    raise ValueError('income group does not exist in df')\n",
        "  else:\n",
        "    \n",
        "    df2 = pd.DataFrame(meta_df)\n",
        "    df3 = pd.DataFrame(population_df)\n",
        "    df2 = df2[df2['Income Group'] == income_group]\n",
        "    #df3 = df3[df3.index.sort_index() == df2.index.sort_index()]\n",
        "    df3 = df3.sort_index()\n",
        "    df2 = df2.sort_index()\n",
        "\n",
        "    a = df3.index.searchsorted(df2.index)\n",
        "    \n",
        "    df3 = df3.iloc[a]\n",
        "    df = pd.melt(df3, var_name='Year', value_name='Population')\n",
        "    df =df.groupby(['Year'])[['Population']].sum()\n",
        "    #df = df.drop(['Country Code'],axis=1) \n",
        "    \n",
        "    array_1 = df['Population'].astype(np.int64)  \n",
        "    array_2 = df.index.astype(np.int64)\n",
        "    \n",
        "    df=pd.DataFrame({'Year' : array_2,'Population' : array_1},dtype='int64')\n",
        "    return np.array(df)\n",
        "    return df3\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xREhikslwsnJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1003
        },
        "outputId": "966cc0ae-cf5f-4966-f03f-b03ed86d7de2"
      },
      "source": [
        "get_year_pop_by_income('High income')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[      1960,  769889923],\n",
              "       [      1961,  781225329],\n",
              "       [      1962,  791207437],\n",
              "       [      1963,  801108277],\n",
              "       [      1964,  810900987],\n",
              "       [      1965,  820309686],\n",
              "       [      1966,  829088382],\n",
              "       [      1967,  837479954],\n",
              "       [      1968,  844905494],\n",
              "       [      1969,  854059674],\n",
              "       [      1970,  862276721],\n",
              "       [      1971,  871169187],\n",
              "       [      1972,  880246152],\n",
              "       [      1973,  888486025],\n",
              "       [      1974,  897803169],\n",
              "       [      1975,  906573084],\n",
              "       [      1976,  913843314],\n",
              "       [      1977,  921330504],\n",
              "       [      1978,  928906293],\n",
              "       [      1979,  936836246],\n",
              "       [      1980,  944587066],\n",
              "       [      1981,  952368316],\n",
              "       [      1982,  959759971],\n",
              "       [      1983,  966754949],\n",
              "       [      1984,  973423742],\n",
              "       [      1985,  980143630],\n",
              "       [      1986,  987194728],\n",
              "       [      1987,  994242786],\n",
              "       [      1988, 1001421456],\n",
              "       [      1989, 1009036892],\n",
              "       [      1990, 1017092667],\n",
              "       [      1991, 1025345408],\n",
              "       [      1992, 1031949811],\n",
              "       [      1993, 1040349480],\n",
              "       [      1994, 1048121445],\n",
              "       [      1995, 1057290586],\n",
              "       [      1996, 1064630661],\n",
              "       [      1997, 1071969568],\n",
              "       [      1998, 1078927765],\n",
              "       [      1999, 1085992668],\n",
              "       [      2000, 1092825678],\n",
              "       [      2001, 1100293969],\n",
              "       [      2002, 1107836355],\n",
              "       [      2003, 1115390519],\n",
              "       [      2004, 1123325037],\n",
              "       [      2005, 1131426281],\n",
              "       [      2006, 1140084827],\n",
              "       [      2007, 1149238990],\n",
              "       [      2008, 1158965286],\n",
              "       [      2009, 1167712409],\n",
              "       [      2010, 1175649232],\n",
              "       [      2011, 1181451343],\n",
              "       [      2012, 1188796100],\n",
              "       [      2013, 1196212921],\n",
              "       [      2014, 1203819897],\n",
              "       [      2015, 1211252041],\n",
              "       [      2016, 1218629612],\n",
              "       [      2017, 1225514228]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTkUMlWrwsnN",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "get_year_pop_by_income('High income')\n",
        "```\n",
        "> ```\n",
        "array([[      1960,  769889923],\n",
        "       [      1961,  781225329],\n",
        "       [      1962,  791207437],\n",
        "       [      1963,  801108277],\n",
        "       ...\n",
        "       [      2015, 1211252041],\n",
        "       [      2016, 1218629612],\n",
        "       [      2017, 1225514228]])\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0CqE2zPwsnO",
        "colab_type": "text"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Now that we have have our data, we need to split this into a set of variables we will be training on, and the set of variables that we will make our predictions on.\n",
        "\n",
        "Unlike the previous coding challenges, a friend of our has indicated that sklearn has its own built-in functionality for creating training and testing sets. Here, using the `train_test_split` [method](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), we can easily shuffle and randomly choose a subset of the data as the test set.   \n",
        "\n",
        "Using this knowledge, write a function which uses sklearn's `train_test_split` [method](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) internally, and that will take as input a 2-d numpy array and return four variables in the form of `(X_train, y_train), (X_test, y_test)`, where `(X_train, y_train)` are the features / response of the training set, and `(X-test, y_test)` are the feautes / response of the testing set. \n",
        "\n",
        "**Important Note:** Due to the random initialisation process used within sklearn's `train_test_split` method, you will need to fix the value of the `random_state` argument in order to get repeatable and predictable results. \n",
        "\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take a 2-d numpy `array` as input.\n",
        "* Should use sklearn's `train_test_split` [method](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
        "* Set `random_state` to equal `42` for this internal method.  \n",
        "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`.\n",
        "* `(X_test, y_test)` should contain 1% of the input array. They should also be the form of an `array`, and not as a single value.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdbpahCXwsnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def sklearn_feature_response_split(arr):\n",
        "  arr = np.array(arr)\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  if arr.shape == (len(arr),2):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(arr[0:,0], arr[0:,1], test_size=0.01, random_state=42)\n",
        "    return (np.array(X_train), np.array(y_train)), (np.array(X_test), np.array(y_test))\n",
        "  else:\n",
        "    return 'all'\n",
        "    \n",
        " \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrDUJvy4wsnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "b4c952c3-5624-4f3c-b3b6-9b7970be32ae"
      },
      "source": [
        "data = get_year_pop_by_income('High income');\n",
        "sklearn_feature_response_split(data)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([1965, 1990, 1973, 1994, 2015, 1987, 1991, 2005, 1972, 2007, 1963,\n",
              "         2003, 1986, 1968, 1977, 1966, 1964, 2000, 1979, 1996, 2008, 1997,\n",
              "         2013, 1975, 1969, 1976, 1984, 1993, 2014, 2012, 1985, 1971, 1992,\n",
              "         2010, 2009, 1989, 2001, 1961, 1981, 1962, 2004, 1999, 1995, 1983,\n",
              "         2006, 1970, 1982, 1978, 2016, 1980, 1967, 2002, 1974, 1988, 2011,\n",
              "         1998]),\n",
              "  array([ 820309686, 1017092667,  888486025, 1048121445, 1211252041,\n",
              "          994242786, 1025345408, 1131426281,  880246152, 1149238990,\n",
              "          801108277, 1115390519,  987194728,  844905494,  921330504,\n",
              "          829088382,  810900987, 1092825678,  936836246, 1064630661,\n",
              "         1158965286, 1071969568, 1196212921,  906573084,  854059674,\n",
              "          913843314,  973423742, 1040349480, 1203819897, 1188796100,\n",
              "          980143630,  871169187, 1031949811, 1175649232, 1167712409,\n",
              "         1009036892, 1100293969,  781225329,  952368316,  791207437,\n",
              "         1123325037, 1085992668, 1057290586,  966754949, 1140084827,\n",
              "          862276721,  959759971,  928906293, 1218629612,  944587066,\n",
              "          837479954, 1107836355,  897803169, 1001421456, 1181451343,\n",
              "         1078927765])),\n",
              " (array([1960]), array([769889923])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bT5qzh5wsnV",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "data = get_year_pop_by_income('High income')\n",
        "sklearn_feature_response_split(data)\n",
        "```\n",
        "> ```\n",
        "((array([1965, 1994, 1973, 2004, 2012, 1997, 1985, 2006, 1972, 2008, 1963,\n",
        "         1996, 1991, 1968, 1977, 1966, 1964, 2001, 1979, 1990, 2009, 2010,\n",
        "         2014, 1975, 1969, 1987, 1986, 1976, 1984, 1993, 2015, 2000, 1971,\n",
        "         1992, 2016, 2003, 1989, 2013, 1961, 1981, 1962, 2005, 1999, 1995,\n",
        "         1983, 2007, 1970, 1982, 1978, 2017, 1980, 1967, 2002, 1974, 1988,\n",
        "         2011, 1998]),\n",
        "  array([ 820309686, 1048121445,  888486025, 1123325037, 1188796100,\n",
        "         1071969568,  980143630, 1140084827,  880246152, 1158965286,\n",
        "          801108277, 1064630661, 1025345408,  844905494,  921330504,\n",
        "          829088382,  810900987, 1100293969,  936836246, 1017092667,\n",
        "         1167712409, 1175649232, 1203819897,  906573084,  854059674,\n",
        "          994242786,  987194728,  913843314,  973423742, 1040349480,\n",
        "         1211252041, 1092825678,  871169187, 1031949811, 1218629612,\n",
        "         1115390519, 1009036892, 1196212921,  781225329,  952368316,\n",
        "          791207437, 1131426281, 1085992668, 1057290586,  966754949,\n",
        "         1149238990,  862276721,  959759971,  928906293, 1225514228,\n",
        "          944587066,  837479954, 1107836355,  897803169, 1001421456,\n",
        "         1181451343, 1078927765])),\n",
        " (array([1960]), array([769889923])))\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeHE5qYUwsnW",
        "colab_type": "text"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Now that we have formatted our data, we can fit a model using sklearn's `DecisionTreeRegressor` class. We'll write a function that will take as input the features and response variables that we created in the last question, and return a trained model.\n",
        "\n",
        "**Important Note:** Due to the random initialisation process used within sklearn's `DecisionTreeRegressor` class, you will need to fix the value of the `random_state` argument in order to get repeatable and predictable results.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
        "* Should return an sklearn `RandomForestRegressor` model.\n",
        "* Set the `random_state` argument of the model to equal `42`\n",
        "* The returned model should be fitted to the data.\n",
        "\n",
        "_**Hint:**_\n",
        "You may need to reshape the data within the function. You can use `.reshape(-1, 1)` to do this.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i57h5eLIwsnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(X_train, y_train):\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    reg = RandomForestRegressor(random_state =42, n_estimators=10)\n",
        "    reg.fit(X_train.reshape(-1, 1),y_train.ravel())\n",
        "    return reg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YukkGOs4wsna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a119176-a318-4e4f-a70b-40ef1b2b2e45"
      },
      "source": [
        "data = get_year_pop_by_income('High income')\n",
        "(X_train, y_train), _ = sklearn_feature_response_split(data)\n",
        "\n",
        "train_model(X_train, y_train).predict([[1960]])"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.86208256e+08])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjSDSmhywsnd",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "train_model(X_train, y_train).predict([[1960]]) == array([7.86208256e+08])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P6VRJdFwsnf",
        "colab_type": "text"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "We would now like to test on our testing data that we produced from Question 2. This test will give the Mean Absolute Error (MAE), which is given by:\n",
        "\n",
        "$$\n",
        "MAE = \\frac{1}{N} \\sum_{n=i}^N |p_i - y_i|\n",
        "$$\n",
        "\n",
        "where $p_i$ refers to the $i^{\\rm th}$ prediction made from `X_test`, $y_i$ refers to the $i^{\\rm th}$ value in `y_test`, and $N$ is the length of `y_test`.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take a trained model and two `arrays` as input. This will be the `X_test` and `y_test` variables from Question 2. \n",
        "* Should return the residual sum of squares over the input from the predicted values of `X_test` as compared to values of `y_test`.\n",
        "* The output should be a `float` rounded to 2 decimal places."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uypW9tdwsng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, X_test, y_test):\n",
        "  y_pred = model.predict(X_test.reshape(-1,1))\n",
        "  return np.round(np.sum(np.absolute(y_test.ravel() - y_pred)),2)\n",
        "\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZkTyb_Nwsni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = get_year_pop_by_income('High income')\n",
        "(X_train, y_train), (X_test, y_test) = sklearn_feature_response_split(data)\n",
        "lm = train_model(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT1Cwptywsnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ea5c701-0025-4539-932f-72e76204038e"
      },
      "source": [
        "test_model(lm, X_test, y_test)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16318333.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSivyxTuwsnq",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "test_model(lm, X_test, y_test) == 16318333.2\n",
        "```"
      ]
    }
  ]
}